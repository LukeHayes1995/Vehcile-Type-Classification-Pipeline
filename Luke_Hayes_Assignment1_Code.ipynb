{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Luke_Hayes_Assignment1_Code.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0v2A3-BPShz-",
        "outputId": "5f841db5-f1b2-47f1-ec09-66ed2029fe3d"
      },
      "source": [
        "#USE GOOGLE DRIVE FOR FOLES TO \n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQlO2HBiTyKe"
      },
      "source": [
        "#SPECIFIC VERSIONS OF TENSORFLOW AND KERAS ARE REQUIRED TO RUN WITH DARKNET AND MY MODEL\n",
        "#TRIED TO USE THE KERAS MODEL IN THE INSTRUCTIONS BUT IT WAS BUILT ON THE PREVIOUS TENSORFLOW\n",
        "#WITH MY MODEL BEING BUILT ON TENSORFLOW 2.0 THERE WAS HUGE ISSUES WITH TRYING TO USE THE MODEL\n",
        "\n",
        "!pip install tensorflow==2.4.0\n",
        "!pip install keras==2.1.5 \n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5rB-twATzto",
        "outputId": "15c0d65b-6eb1-4da2-e816-f45e06a7fb02"
      },
      "source": [
        "#HERE WE CREATE THE TRAINING AND VALIDATION DATA FROM THE FOLDERS OF IMAGES THAT I HAVE FOR MY PROJECT\n",
        "#I HAVE A TOTAL OF 800 OF EACH TYPE OF IMAGE\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/gdrive/MyDrive/dataset/dataset2/\",\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",  # categorical, binary\n",
        "    class_names=['sedan', 'suv'],\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    image_size=(416, 416),  # reshape if not in this size\n",
        "    shuffle=True,\n",
        "    seed=123,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/gdrive/MyDrive/dataset/dataset2/\",\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",  # categorical, binary\n",
        "    class_names=['sedan', 'suv'],\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    image_size=(416, 416),  # reshape if not in this size\n",
        "    shuffle=True,\n",
        "    seed=123,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1600 files belonging to 2 classes.\n",
            "Using 1280 files for training.\n",
            "Found 1600 files belonging to 2 classes.\n",
            "Using 320 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkH2QRVfgtYK"
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "#HERE IS WHERE E DO SOME DATA AUGMENTATION\n",
        "#WE DO A RANDOM HORIZONTAL FLIPS AND ROTATION ON SOME OF THE DATA \n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "        layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPjXjT0Jf3Pu",
        "outputId": "9d85cd6a-137e-4f6b-b41a-eb0e932ca4f2"
      },
      "source": [
        "# MOBILENET MODE TRAINED ON IMAGENT DATASET\n",
        "base_model = keras.applications.MobileNet(\n",
        "    weights=\"imagenet\",  \n",
        "    input_shape=(416, 416, 3),\n",
        "    include_top=False,\n",
        ")  \n",
        "\n",
        "print(train_ds)\n",
        "\n",
        "# KEEP THE BASE MODEL FOR LATER DONT TRAIN STRAIGHT AWAY\n",
        "base_model.trainable = False\n",
        "\n",
        "# HERE WE CREATE THE NEW MODEL ON TOP OF THE BASE MODEL \n",
        "inputs = keras.Input(shape=(416, 416, 3))\n",
        "# HERE WE APPLY THE DATA AUGMENTATION AT RANDOM\n",
        "x = data_augmentation(inputs) \n",
        "\n",
        "\n",
        "#HERE WE DO SOME NORMALIZATION OF THE INPUT IMAGE DATA TO (-1,1)\n",
        "norm_layer = keras.layers.experimental.preprocessing.Normalization()\n",
        "mean = np.array([127.5] * 3)\n",
        "var = mean ** 2\n",
        "x = norm_layer(x)\n",
        "norm_layer.set_weights([mean, var])\n",
        "\n",
        "# WE WILL KEEP THE BASE MODEL FROM TRAINING SO WE CAN DO SOME FINE TUNING LATER\n",
        "x = base_model(x, training=False)\n",
        "# USE AVERAGE POOLING LAYER TO \n",
        "# REDUCE SIZE OF REPRESENTATION AND SPEED UP COMPUTATION\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "#IMPLEMENT RANDOM DROPOUT OF SOME OF THE NN NODES \n",
        "#MAKES THE NN NOT RELY ON ANY ONE FEATURE AS IT CAN GO AWAY BASICALLY \n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "# ADD A SIMPLE DENSE LAYER WITH TWO OUTPUTS \n",
        "outputs = keras.layers.Dense(2)(x)\n",
        "# NOW WE HAVE THE MODEL\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "<BatchDataset shapes: ((None, 416, 416, 3), (None, 2)), types: (tf.float32, tf.float32)>\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 416, 416, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 416, 416, 3)       0         \n",
            "_________________________________________________________________\n",
            "normalization (Normalization (None, 416, 416, 3)       7         \n",
            "_________________________________________________________________\n",
            "mobilenet_1.00_224 (Function (None, 13, 13, 1024)      3228864   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 3,230,921\n",
            "Trainable params: 2,050\n",
            "Non-trainable params: 3,228,871\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaWgrDFuk2Sb",
        "outputId": "70b64074-721d-41e0-f3fc-c734ca722fa6"
      },
      "source": [
        "# HERE WE USE ADAM INSTEAD OF SGD\n",
        "# BinaryCrossentropy AS OUR LOSS FUNCTION\n",
        "# AND BINARY ACCURACY AS OUT ACCURACY METRIC\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "    metrics=[keras.metrics.BinaryAccuracy()],\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "print(train_ds)\n",
        "\n",
        "##WE DO SOME TRAINING \n",
        "epochs = 20\n",
        "model.fit(train_ds, epochs=epochs, validation_data=val_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 416, 416, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_3 (Sequential)    (None, 416, 416, 3)       0         \n",
            "_________________________________________________________________\n",
            "normalization_2 (Normalizati (None, 416, 416, 3)       7         \n",
            "_________________________________________________________________\n",
            "mobilenet_1.00_224 (Function (None, 13, 13, 1024)      3228864   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 3,230,921\n",
            "Trainable params: 2,050\n",
            "Non-trainable params: 3,228,871\n",
            "_________________________________________________________________\n",
            "<BatchDataset shapes: ((None, 416, 416, 3), (None, 2)), types: (tf.float32, tf.float32)>\n",
            "Epoch 1/20\n",
            "40/40 [==============================] - 15s 291ms/step - loss: 0.7232 - binary_accuracy: 0.5190 - val_loss: 0.6016 - val_binary_accuracy: 0.5734\n",
            "Epoch 2/20\n",
            "40/40 [==============================] - 13s 283ms/step - loss: 0.6012 - binary_accuracy: 0.6265 - val_loss: 0.5239 - val_binary_accuracy: 0.6906\n",
            "Epoch 3/20\n",
            "40/40 [==============================] - 13s 283ms/step - loss: 0.5395 - binary_accuracy: 0.6997 - val_loss: 0.4724 - val_binary_accuracy: 0.7641\n",
            "Epoch 4/20\n",
            "40/40 [==============================] - 12s 281ms/step - loss: 0.4910 - binary_accuracy: 0.7454 - val_loss: 0.4317 - val_binary_accuracy: 0.8078\n",
            "Epoch 5/20\n",
            "40/40 [==============================] - 13s 285ms/step - loss: 0.4587 - binary_accuracy: 0.7793 - val_loss: 0.4034 - val_binary_accuracy: 0.8266\n",
            "Epoch 6/20\n",
            "40/40 [==============================] - 13s 286ms/step - loss: 0.4395 - binary_accuracy: 0.7901 - val_loss: 0.3937 - val_binary_accuracy: 0.8156\n",
            "Epoch 7/20\n",
            "40/40 [==============================] - 12s 275ms/step - loss: 0.4166 - binary_accuracy: 0.8077 - val_loss: 0.3687 - val_binary_accuracy: 0.8469\n",
            "Epoch 8/20\n",
            "40/40 [==============================] - 12s 272ms/step - loss: 0.4006 - binary_accuracy: 0.8197 - val_loss: 0.3631 - val_binary_accuracy: 0.8313\n",
            "Epoch 9/20\n",
            "40/40 [==============================] - 12s 277ms/step - loss: 0.3915 - binary_accuracy: 0.8146 - val_loss: 0.3486 - val_binary_accuracy: 0.8484\n",
            "Epoch 10/20\n",
            "40/40 [==============================] - 12s 276ms/step - loss: 0.3811 - binary_accuracy: 0.8282 - val_loss: 0.3470 - val_binary_accuracy: 0.8375\n",
            "Epoch 11/20\n",
            "40/40 [==============================] - 12s 272ms/step - loss: 0.3593 - binary_accuracy: 0.8318 - val_loss: 0.3389 - val_binary_accuracy: 0.8438\n",
            "Epoch 12/20\n",
            "40/40 [==============================] - 12s 277ms/step - loss: 0.3645 - binary_accuracy: 0.8263 - val_loss: 0.3183 - val_binary_accuracy: 0.8625\n",
            "Epoch 13/20\n",
            "40/40 [==============================] - 12s 273ms/step - loss: 0.3546 - binary_accuracy: 0.8464 - val_loss: 0.3324 - val_binary_accuracy: 0.8516\n",
            "Epoch 14/20\n",
            "40/40 [==============================] - 12s 275ms/step - loss: 0.3394 - binary_accuracy: 0.8533 - val_loss: 0.3235 - val_binary_accuracy: 0.8500\n",
            "Epoch 15/20\n",
            "40/40 [==============================] - 12s 273ms/step - loss: 0.3294 - binary_accuracy: 0.8586 - val_loss: 0.3217 - val_binary_accuracy: 0.8547\n",
            "Epoch 16/20\n",
            "40/40 [==============================] - 12s 274ms/step - loss: 0.3377 - binary_accuracy: 0.8473 - val_loss: 0.3144 - val_binary_accuracy: 0.8562\n",
            "Epoch 17/20\n",
            "40/40 [==============================] - 12s 275ms/step - loss: 0.3258 - binary_accuracy: 0.8502 - val_loss: 0.3073 - val_binary_accuracy: 0.8609\n",
            "Epoch 18/20\n",
            "40/40 [==============================] - 12s 272ms/step - loss: 0.3188 - binary_accuracy: 0.8554 - val_loss: 0.2886 - val_binary_accuracy: 0.8844\n",
            "Epoch 19/20\n",
            "40/40 [==============================] - 12s 272ms/step - loss: 0.3308 - binary_accuracy: 0.8596 - val_loss: 0.2889 - val_binary_accuracy: 0.8766\n",
            "Epoch 20/20\n",
            "40/40 [==============================] - 12s 274ms/step - loss: 0.3106 - binary_accuracy: 0.8596 - val_loss: 0.3055 - val_binary_accuracy: 0.8594\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5d400e55d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uV7rtVi6OJMq",
        "outputId": "4da0e35c-b7b1-4237-ad43-890ec686f401"
      },
      "source": [
        "#NOW WE TRAIN THE BASE MODEL AS A MEANS OF DOING SOME FINE TUNING TRAINING\n",
        "#SO ESENTIALLY WE TRAIN USING OUR MODEL ON MY TRAINING DATA\n",
        "#THEN WE FINE TUNE THIS USING THE BASE MODEL (MOBILENET)\n",
        "#ALSO USE A VERY LOW LEARNING RATE \n",
        "base_model.trainable = True\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-5), \n",
        "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "    metrics=[keras.metrics.BinaryAccuracy()],\n",
        ")\n",
        "\n",
        "epochs = 10\n",
        "model.fit(train_ds, epochs=epochs, validation_data=val_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 416, 416, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_3 (Sequential)    (None, 416, 416, 3)       0         \n",
            "_________________________________________________________________\n",
            "normalization_2 (Normalizati (None, 416, 416, 3)       7         \n",
            "_________________________________________________________________\n",
            "mobilenet_1.00_224 (Function (None, 13, 13, 1024)      3228864   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 3,230,921\n",
            "Trainable params: 3,209,026\n",
            "Non-trainable params: 21,895\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "40/40 [==============================] - 34s 747ms/step - loss: 0.3481 - binary_accuracy: 0.8354 - val_loss: 0.2418 - val_binary_accuracy: 0.9078\n",
            "Epoch 2/10\n",
            "40/40 [==============================] - 30s 736ms/step - loss: 0.2716 - binary_accuracy: 0.8817 - val_loss: 0.2401 - val_binary_accuracy: 0.9031\n",
            "Epoch 3/10\n",
            "40/40 [==============================] - 31s 740ms/step - loss: 0.2275 - binary_accuracy: 0.9099 - val_loss: 0.2040 - val_binary_accuracy: 0.9156\n",
            "Epoch 4/10\n",
            "40/40 [==============================] - 31s 738ms/step - loss: 0.2289 - binary_accuracy: 0.9011 - val_loss: 0.1948 - val_binary_accuracy: 0.9250\n",
            "Epoch 5/10\n",
            "40/40 [==============================] - 31s 735ms/step - loss: 0.1926 - binary_accuracy: 0.9211 - val_loss: 0.1781 - val_binary_accuracy: 0.9281\n",
            "Epoch 6/10\n",
            "40/40 [==============================] - 31s 745ms/step - loss: 0.1954 - binary_accuracy: 0.9227 - val_loss: 0.1942 - val_binary_accuracy: 0.9219\n",
            "Epoch 7/10\n",
            "40/40 [==============================] - 31s 738ms/step - loss: 0.1737 - binary_accuracy: 0.9339 - val_loss: 0.1544 - val_binary_accuracy: 0.9453\n",
            "Epoch 8/10\n",
            "40/40 [==============================] - 31s 741ms/step - loss: 0.1544 - binary_accuracy: 0.9429 - val_loss: 0.1798 - val_binary_accuracy: 0.9312\n",
            "Epoch 9/10\n",
            "40/40 [==============================] - 31s 739ms/step - loss: 0.1579 - binary_accuracy: 0.9445 - val_loss: 0.1617 - val_binary_accuracy: 0.9453\n",
            "Epoch 10/10\n",
            "40/40 [==============================] - 31s 741ms/step - loss: 0.1626 - binary_accuracy: 0.9348 - val_loss: 0.1590 - val_binary_accuracy: 0.9422\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5b101cc8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSqkcHYQW6hM",
        "outputId": "8c7d5f4e-87de-4c49-fae7-f6845fa93fc5"
      },
      "source": [
        "#SAVE THE MODEL SO I DON'T HAVE TO KEEP RUNNING IT \n",
        "model.save('saved_model/my_model_new_softmax1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/my_model_new_softmax1/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYtcSS7pOnxs"
      },
      "source": [
        "#LOAD THE OLD SAVED MODEL \n",
        "#THIS IS WHEN MY COLAB TIMES OUT \n",
        "new_model = tf.keras.models.load_model('/content/gdrive/MyDrive/my_model_new_softmax')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUb6ch_SU22u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f18ba566-4165-43d5-fa49-36af2909083d"
      },
      "source": [
        "#CLONE THE DARKNET LIBRARY\n",
        "#LOAD IN THE WEIGHTS FOR TINY YOLO \n",
        "\n",
        "!git clone https://github.com/AlexeyAB/darknet.git\n",
        "!wget https://pjreddie.com/media/files/yolov3-tiny.weights\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'darknet'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 14748 (delta 2), reused 7 (delta 1), pack-reused 14736\u001b[K\n",
            "Receiving objects: 100% (14748/14748), 13.28 MiB | 9.17 MiB/s, done.\n",
            "Resolving deltas: 100% (10025/10025), done.\n",
            "--2021-04-01 08:54:12--  https://pjreddie.com/media/files/yolov3-tiny.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 35434956 (34M) [application/octet-stream]\n",
            "Saving to: ‘yolov3-tiny.weights’\n",
            "\n",
            "yolov3-tiny.weights 100%[===================>]  33.79M  13.4MB/s    in 2.5s    \n",
            "\n",
            "2021-04-01 08:54:16 (13.4 MB/s) - ‘yolov3-tiny.weights’ saved [35434956/35434956]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R06CRXkaPlF9",
        "outputId": "82ba5399-c4ab-4579-b4d0-6e3c12862efe"
      },
      "source": [
        "#I HAD TO MAKE NUMEROUR CHANGES TO THE DARKNET PROJECT TO \n",
        "#1 ALLOW IT TO BE IMPORTED AS A LIBRARY\n",
        "#2 GET THE LIBRRY TO WORK EITH MY IMAGES \n",
        "#ALSO I HAD TO CHANGE TINY-YOLOT.CFG FILE TO CREATE CORRECT BOUDING BOXES AS INITIALLY\n",
        "#THEY ONLY COVERED A TINY PART OF MY VEHICLES\n",
        "\n",
        "#THEREFOR HERE I NEED TO UPLOAD\n",
        "#1 A NEW DARKNET.PY FILE\n",
        "#2 A NEW MAKEFILE\n",
        "#3 A NEW TINY-YOLO.CFG FILE ALL BEFORE THE NEXT MAKE STEP\n",
        "\n",
        "%cd /content/darknet\n",
        "#NEED TO CHANGE FILES BEFORE EXECUTING NEXT CELL"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/darknet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0LqkXhJZ16-"
      },
      "source": [
        "#NEED TO MAKE CHANGES DON'T MAKE\n",
        "#MAKE THE NEW DARKNET PROJECT \n",
        "######################################################################################################\n",
        "##PLEASE LOOK AT INSTRUCTIONS FILE IN ZIP FILE BEFORE MAKING\n",
        "######################################################################################################\n",
        "!make"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7cp2NGNPtc3"
      },
      "source": [
        "#IMPORT THE PROJECTS DARKNET.PY FILE\n",
        "import darknet as dn\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Q6M9xIpP6iB",
        "outputId": "13586866-6b37-421e-e69f-20c0697c933b"
      },
      "source": [
        "import importlib\n",
        "importlib.reload(dn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'darknet' from '/content/darknet/darknet.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2TKfNT36yhD"
      },
      "source": [
        "#HERE WE CREATE A SOFTMAX LAYER FOR PREDICTION\n",
        "probability_model = tf.keras.Sequential([new_model, tf.keras.layers.Softmax()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rt49KYFQQmE"
      },
      "source": [
        "import cv2 as cv\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import timeit\n",
        "import sys \n",
        "start = 0\n",
        "#THIS IS THE VERSION WITHOUT THE MUTITHREADING OPTIMIZATION \n",
        "\n",
        "#THIS IS THE METHOD THAT IS CALLED WHEN WE ARE LOOKING TO PARSE THE VIDEO\n",
        "\n",
        "throughput_times = []\n",
        "yolo_times = []\n",
        "full_frame_times = []\n",
        "classifier_times = []\n",
        "q1_times = []\n",
        "q2_times = []\n",
        "crop_times = []\n",
        "\n",
        "def getFrame(sec,cval, net, class_names, colors, lis, start, old_time):\n",
        "\n",
        "    #THIS IS THE VIDEO READER\n",
        "    #HERE WE USE THE SEC VALUE WHICH INCREMENTS THE AMOUNT WE NEED TO GET 900\n",
        "    #FRAMES FROM THE GIVEN VIDEO \n",
        "    framestart = timeit.default_timer()\n",
        "    q1start = timeit.default_timer()\n",
        "\n",
        "    vidcap.set(cv.CAP_PROP_POS_MSEC,sec*1000)\n",
        "    hasFrames,image = vidcap.read()\n",
        "    total_vehicles = 0\n",
        "    sedan = 0\n",
        "    suv = 0\n",
        "\n",
        "    #ENTER IF THERE IS A FRAME AND WE HAVEN'T READ MORE THAN 900 FRAMES \n",
        "    if hasFrames and cval <= 900:\n",
        "\n",
        "      #WRITE THE FRAME TO DISK \n",
        "      cv.imwrite(\"/content/gdrive/MyDrive/images/image\"+str(count)+\".jpg\", image)     \n",
        "\n",
        "      #GET THE PATH OF THE FRAME AS MY YOLO TAKES THE PATH AND LOOKS UP THE FILE\n",
        "      #THUS WE HAVE TO WRITE TO DISK AND RE READ IN YOLO\n",
        "      path = \"/content/gdrive/MyDrive/images/image\"+str(count)+\".jpg\"\n",
        "\n",
        "      q1stop = timeit.default_timer()\n",
        "      q1_times.append(q1stop - q1start)\n",
        "      q2start = timeit.default_timer()\n",
        "\n",
        "\n",
        "      #HERE Q2 STARTS SO \n",
        "\n",
        "      #GET THE IMAGE AND THE BOUNDING BOX LOCATIONS FROM YOLO\n",
        "      x, bb = YOLO(path, cval, net, class_names, colors)\n",
        "      image_list = []\n",
        "      val = 0\n",
        "      total_vehicles = 0\n",
        "      sedan = 0\n",
        "      suv = 0\n",
        "\n",
        "      #LOOP THROUGH THE BOUNDING BOX LOCATIONS \n",
        "      for b in bb:\n",
        "        if (b[0] == \"car\"):\n",
        "          #GET THE LOCATIONS AND CROP OUT THE PROPOSED REGIONS FOR THE CAR\n",
        "          left, top, right, bottom = dn.bbox2points(b[2])\n",
        "          image_list.append(cropRegions(image, left,right,top,bottom, val))\n",
        "          val = val + 1\n",
        "      i = 0\n",
        "\n",
        "      #LOOP THROUGH THE CROPPED IMAGES \n",
        "      for image in image_list:\n",
        "        total_vehicles = total_vehicles + 1\n",
        "        #SEND EACH IMAGE TO BE CLASSIFIED\n",
        "        sedanres, suvres = classify(image, i)\n",
        "        #INCREMEMNT THE RESULTS BASED ON WHAT IS CLASSIFIED\n",
        "        sedan = sedan + sedanres\n",
        "        suv = suv + suvres\n",
        "        i = i + 1\n",
        "\n",
        "      #CREATE A TUPLE WITH THE RESULTS FOR THE FRAME \n",
        "      x = (sedan, suv, total_vehicles)\n",
        "      #APPEND THE RESULTS TO A LIST \n",
        "      lis.append(x)\n",
        "\n",
        "      time = timeit.default_timer()\n",
        "\n",
        "\n",
        "      #IF WE HAVE DONE 900 FRAMES THEN WE STOP THE TIMER AND RETURN THE THROUGHPUT\n",
        "      if(cval != 1):\n",
        "        throughput_times.append((time - old_time))\n",
        "      \n",
        "\n",
        "      old_time = time\n",
        "\n",
        "      if (cval == 900):\n",
        "        stop = timeit.default_timer()\n",
        "        print('Throughput (FPS) without optimization is: ', (900 / (stop - start))) \n",
        "\n",
        "      q2stop = timeit.default_timer()\n",
        "      q2_times.append(q2stop - q2start)\n",
        "\n",
        "    framestop = timeit.default_timer()\n",
        "    full_frame_times.append(framestop - framestart)\n",
        "\n",
        "    return hasFrames, lis, start, old_time\n",
        "\n",
        "#YOLO FUNCTIONALITY\n",
        "def YOLO(path, cval, net, class_names, colors):\n",
        "  yolostart = timeit.default_timer()\n",
        "\n",
        "  #WEIGHTS AND DATA ARE NEEDED \n",
        "  weights = \"/content/yolov3-tiny.weights\"\n",
        "  data = \"/content/darknet/cfg/coco.data\"\n",
        "\n",
        "  #SET THE THRESHOLDS \n",
        "  nms_thresh = 0.2\n",
        "  thresh = 0.2\n",
        "  hier_thresh = 0.5\n",
        "\n",
        "  #RUN THE DARKNET TINY YOLO DETECTION ON THE IMAGE \n",
        "  det = dn.detect_image(net, class_names, path.encode('utf-8'), thresh=thresh, hier_thresh=hier_thresh, nms=nms_thresh)\n",
        "\n",
        "  #RETUNR THE IMAGE AND THE THE BB LIST OF ALL THE POSSIBLE VEHICLES\n",
        "  newimage, bblist = dn.draw_boxes(det, path, colors)\n",
        "\n",
        "  yolostop = timeit.default_timer()\n",
        "\n",
        "  yolo_times.append(yolostop - yolostart)\n",
        "\n",
        "  return newimage, det\n",
        "\n",
        "#CROP THE REGION OF INTEREST FROM THE IMAGE \n",
        "def cropRegions(image, left,right,top,bottom, val):\n",
        "  cropstart = timeit.default_timer()\n",
        "  #SOMETIMES YOLO CAN GIVE NEGATIVE LOCATIONS WHICH WE SET TO 0 \n",
        "  if left < 0:\n",
        "    left = 0\n",
        "  if right < 0:\n",
        "    right = 0\n",
        "  if top < 0:\n",
        "    top = 0\n",
        "  if bottom < 0:\n",
        "    bottom = 0\n",
        "  \n",
        "  #CROP\n",
        "  image = image[top:bottom, left:right]\n",
        "  crop_stop = timeit.default_timer()\n",
        "  crop_times.append(crop_stop - cropstart)\n",
        "\n",
        "\n",
        "  return image \n",
        "\n",
        "\n",
        "def classify(img, i):\n",
        "  classifierstart = timeit.default_timer()\n",
        "\n",
        "  #WE NEED TO RESIZE THE IMAGE \n",
        "  dim = (416, 416)\n",
        "  resized = cv.resize(img, dim, interpolation = cv.INTER_AREA)\n",
        "\n",
        "  #WE NEED TO GIVE IT ANOTHER DIMENSION TO MATCH THE CLASSIFIER\n",
        "  img = np.expand_dims(resized, axis=0)\n",
        "  #USE OUR MODEL TO REUTN A PROBABILITY OF IT BEING A SUV AND A PROBABILITY OF IT BEING A SEDAN \n",
        "  predictions_single = probability_model.predict(img)\n",
        "  #WE TAKE THE BIGGEST PROB AS OUR PREDICTION\n",
        "  class_res = np.argmax(predictions_single)\n",
        "  sedan = 0\n",
        "  suv = 0\n",
        "\n",
        "  #SET OUT PREDICTION VALUES THAT WE RETURN FOR OUR RESULTS\n",
        "  if class_res == 0:\n",
        "    sedan = 1\n",
        "\n",
        "  elif class_res == 1:\n",
        "    suv = 1\n",
        "\n",
        "  classifierstop = timeit.default_timer()\n",
        "\n",
        "  classifier_times.append(classifierstop - classifierstart)\n",
        "\n",
        "  return sedan, suv\n",
        "\n",
        "#VIDEO LOCATION\n",
        "vidcap = cv.VideoCapture('/content/assignment-clip.mp4')\n",
        "cval = 1\n",
        "\n",
        "count = 1\n",
        "bb = []\n",
        "sec = 0\n",
        "\n",
        "#THIS FRAME RATE GIVES US 900 IMAGES IN 30 SECONDS OF VIDEO \n",
        "frameRate = 1/30 \n",
        "count=1\n",
        "model = \"/content/darknet/cfg/yolov3-tiny.cfg\"\n",
        "weights = \"/content/yolov3-tiny.weights\"\n",
        "data = \"/content/darknet/cfg/coco.data\"\n",
        "\n",
        "#WE NEED THIS NETWORK \n",
        "net, class_names, colors = dn.load_network(model, data, weights, 0)\n",
        "\n",
        "#READ IN THE GROUND TRUTH DATA SO WE CAN COMPARE \n",
        "df = pd.read_excel(\"/content/gdrive/MyDrive/Groundtruth.xlsx\", sheet_name = 'Sheet2')\n",
        "#PUT THE RESULTS INTO THEIR OWN LISTS\n",
        "frames = pd.DataFrame(df['Frame#'])\n",
        "sedans = pd.DataFrame(df['Sedan'])\n",
        "suvs = pd.DataFrame(df['SUV'])\n",
        "total = pd.DataFrame(df['Total'])\n",
        "\n",
        "#CONVERT TO NUMPY\n",
        "total = total.to_numpy()\n",
        "sedans = sedans.to_numpy()\n",
        "suvs = suvs.to_numpy()\n",
        "frames = frames.to_numpy()\n",
        "\n",
        "result = []\n",
        "old_time = 0\n",
        "#START THE TIMER AND SET OFF THE PROCESS OF READING IN THE\n",
        "start = timeit.default_timer()\n",
        "success, res, start, old_time = getFrame(sec,cval, net, class_names, colors, result, start, old_time)\n",
        "\n",
        "#LOOP UNTIL THERE ARE NO MORE FRAMES \n",
        "while success:\n",
        "    cval = cval + 1\n",
        "    count = count + 1\n",
        "    sec = sec + frameRate\n",
        "    success, res, start, old_time = getFrame(sec,cval, net, class_names, colors, result, start, old_time)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BC81l_Xlypm"
      },
      "source": [
        "print(q1_times)\n",
        "print(q2_times)\n",
        "print(throughput_times)\n",
        "print(yolo_times)\n",
        "print(classifier_times)\n",
        "\n",
        "#WE COULD GET THE AVEAGE OF ALL THESE AND PUT THEM INTO A TABLE \n",
        "\n",
        "print(\"The average Q1 time is \", (sum(q1_times)/len(q1_times)))\n",
        "print(\"The average Q2 time is \", (sum(q2_times)/len(q2_times)))\n",
        "print(\"The average Throughput time is \", (sum(throughput_times)/len(throughput_times)))\n",
        "print(\"The average YOLO time is \", (sum(yolo_times)/len(yolo_times)))\n",
        "print(\"The average Classifier time is \", (sum(classifier_times)/len(classifier_times)))\n",
        "print(\"The average cropping time is \", (sum(crop_times)/len(crop_times)))\n",
        "#THEN LETS WRITE Q1 Q2 AND THROUGHPUT TO A .CSV FILE AND PLOT\n",
        "\n",
        "\n",
        "with open('/content/results.csv','w') as out:\n",
        "    csv_out=csv.writer(out)\n",
        "    csv_out.writerow(['Q1 Times','Q2 Times', 'Throughput'])\n",
        "    for i in range(len(throughput_times)):\n",
        "        resnew = ((q1_times[i]) ,q2_times[i], throughput_times[i])\n",
        "        csv_out.writerow(resnew)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6S_hq7MOl8L_"
      },
      "source": [
        "#THIS IS THE FUNCTIONS FOR THE PART WITH OPTIMIZATION WITH A FEW MINOR ALTERATIONS\n",
        "#NO NEED TO COMMENT AGAIN AS THERE ARE TINY DIFFEENCES \n",
        "\n",
        "def getFrame2(sec,cval, vid):\n",
        "    done = False\n",
        "    vid.set(cv.CAP_PROP_POS_MSEC,sec*1000)\n",
        "    hasFrames,image = vid.read()\n",
        "    if hasFrames and cval <= 900:\n",
        "      cv.imwrite(\"/content/gdrive/MyDrive/images/image\"+str(cval)+\".jpg\", image)     # save frame as JPG file\n",
        "      path = \"/content/gdrive/MyDrive/images/image\"+str(cval)+\".jpg\"\n",
        "    else:\n",
        "      path = \"\"\n",
        "      hasFrames = False\n",
        "\n",
        "    if (cval == 900):\n",
        "      done = True\n",
        "    return hasFrames, path, done\n",
        "\n",
        "\n",
        "def YOLO2(path, cval, net, class_names, colors):\n",
        "  weights = \"/content/yolov3-tiny.weights\"\n",
        "  data = \"/content/darknet/cfg/coco.data\"\n",
        "\n",
        "  \n",
        "  nms_thresh = 0.2\n",
        "  thresh = 0.2\n",
        "  hier_thresh = 0.5\n",
        "  \n",
        "  det = dn.detect_image(net, class_names, path.encode('utf-8'), thresh=thresh, hier_thresh=hier_thresh, nms=nms_thresh)\n",
        "  newimage, bblist = dn.draw_boxes(det, path, colors)\n",
        "  return newimage, det\n",
        "\n",
        "def cropRegions(image, left,right,top,bottom, val):\n",
        "  if left < 0:\n",
        "    left = 0\n",
        "  if right < 0:\n",
        "    right = 0\n",
        "  if top < 0:\n",
        "    top = 0\n",
        "  if bottom < 0:\n",
        "    bottom = 0\n",
        "  image = image[top:bottom, left:right]\n",
        "\n",
        "  return image \n",
        "\n",
        "def classify(img, i):\n",
        "\n",
        "  dim = (416, 416)\n",
        "  resized = cv.resize(img, dim, interpolation = cv.INTER_AREA)\n",
        "\n",
        "  img = np.expand_dims(resized, axis=0)\n",
        "  predictions_single = probability_model.predict(img)\n",
        "  class_res = np.argmax(predictions_single)\n",
        "  sedan = 0\n",
        "  suv = 0\n",
        "\n",
        "  if class_res == 0:\n",
        "    sedan = 1\n",
        "\n",
        "  elif class_res == 1:\n",
        "    suv = 1\n",
        "\n",
        "  return sedan, suv\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fw6Xy7Iz9Fdf"
      },
      "source": [
        "This is the example with the optimization of multithreading included. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFd9oRhmalw-",
        "outputId": "64f558af-6182-46a8-93b9-7c78b8dde98a"
      },
      "source": [
        "import cv2 as cv\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "from threading import Thread, Lock\n",
        "import time\n",
        "import random\n",
        "import queue\n",
        "import threading\n",
        "from threading import Condition\n",
        "import sys\n",
        "import timeit\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "#HERE WE USE A QUEUE WHICH MAKES IT THREAD SAFE AND ALSO SENDS NOTIFICATIONS \n",
        "#WHEN DATA HAS BEEN ADDED OR REMOVED \n",
        "q = queue.Queue()\n",
        "#LIST FOR THE THREADS \n",
        "threads = list()\n",
        "\n",
        "#ALL THE SAME AS IN LAST EXAMPLE\n",
        "count = 1\n",
        "bb = []\n",
        "\n",
        "frameRate = 1/30 \n",
        "count=1\n",
        "model = \"/content/darknet/cfg/yolov3-tiny.cfg\"\n",
        "weights = \"/content/yolov3-tiny.weights\"\n",
        "data = \"/content/darknet/cfg/coco.data\"\n",
        "net, class_names, colors = dn.load_network(model, data, weights, 0)\n",
        "\n",
        "\n",
        "df = pd.read_excel(\"/content/gdrive/MyDrive/Groundtruth.xlsx\", sheet_name = 'Sheet2')\n",
        "frames = pd.DataFrame(df['Frame#'])\n",
        "sedans = pd.DataFrame(df['Sedan'])\n",
        "suvs = pd.DataFrame(df['SUV'])\n",
        "total = pd.DataFrame(df['Total'])\n",
        "\n",
        "\n",
        "total = total.to_numpy()\n",
        "sedans = sedans.to_numpy()\n",
        "suvs = suvs.to_numpy()\n",
        "frames = frames.to_numpy()\n",
        "\n",
        "result = []\n",
        "\n",
        "throughput_times = []\n",
        "\n",
        "\n",
        "#THIS IS THE PRODUCER THREAD WHICH IS THE VIDEO READER\n",
        "#IT TAKES THE VIDEO AND PUTS THE OUTPUT WHICH IS A FRAME INTO THE QUEUE\n",
        "class ProducerThread(Thread):\n",
        "    Thread._is_running = True\n",
        "    def run(self):\n",
        "        start = timeit.default_timer()\n",
        "        frameRate = 1/30 \n",
        "        global queue\n",
        "        sec = 0\n",
        "        cval = 1\n",
        "        hasFrames = True\n",
        "        vid = cv.VideoCapture('/content/assignment-clip.mp4')\n",
        "\n",
        "        #LOOP HERE WHILE THE THREAD IS ALIVE \n",
        "        while (self._is_running):\n",
        "\n",
        "            hasFrame, path, done = getFrame2(sec,cval, vid)\n",
        "            #IF WE ARE DONE END THREAD\n",
        "            if (done):\n",
        "              stop = timeit.default_timer()\n",
        "              print('Throughput (FPS) with optimization of part 1 is: ', (900 / (stop - start))) \n",
        "              self.stop()\n",
        "\n",
        "            sec = sec + frameRate\n",
        "            cval = cval + 1\n",
        "            q.put(path)\n",
        "\n",
        "    def stop(self):\n",
        "      self._is_running = False\n",
        "\n",
        "\n",
        "#THIS THREAD TAKES THE FRAMES PATH OFF THE QUEUE AND RUNS YOLO, CROPS THE IMAGES\n",
        "#AND RUNS THE CLASSIFIER ON EACH PROPOSED VEHICLE\n",
        "class ConsumerThread(Thread):\n",
        "    Thread._is_running = True\n",
        "    net, class_names, colors = dn.load_network(model, data, weights, 0)\n",
        "\n",
        "    def run(self):\n",
        "        main_start = timeit.default_timer()\n",
        "\n",
        "        start = timeit.default_timer()\n",
        "        stop = \"\"\n",
        "        global queue\n",
        "        counter = 0\n",
        "        output = []\n",
        "        img_array = []\n",
        "\n",
        "        while (self._is_running):\n",
        "            main_start = timeit.default_timer()\n",
        "\n",
        "            #TAKE PATH FROM QUEUE \n",
        "            path = q.get()\n",
        "            if (path != \"\"):\n",
        "              counter = counter + 1\n",
        "\n",
        "            #RUN YOLO ON IMAGE \n",
        "            x, bb = YOLO2(path, counter, net, class_names, colors)\n",
        "            image_list = []\n",
        "            val = 0\n",
        "            total_vehicles = 0\n",
        "            sedan = 0\n",
        "            suv = 0\n",
        "            i = 0\n",
        "\n",
        "            #we need to look up the image here so we can add the boxes and the labels\n",
        "            frame = cv.imread(\"/content/gdrive/MyDrive/images/image\"+str(counter)+\".jpg\")     # save frame as JPG file\n",
        "\n",
        "            #LOOP THROUGH BOUNDING BOXES \n",
        "            for b in bb:\n",
        "              if (b[0] == \"car\"):\n",
        "                left, top, right, bottom = dn.bbox2points(b[2])\n",
        "                image = cropRegions(x, left,right,top,bottom, val)\n",
        "                val = val + 1\n",
        "                total_vehicles = total_vehicles + 1\n",
        "                sedanres, suvres = classify(image, i)\n",
        "                label = \"\"\n",
        "                col = (0,255,0)\n",
        "\n",
        "                #HERE WE ANNOTATE EACH FRAME WITH THE BOUNDING BOX AND THE LABEL OF THE PREDICTION\n",
        "                if (sedanres == 1):\n",
        "                  label = \"Sedan\"\n",
        "                  cv.rectangle(frame, (left, top), (right, bottom), (0,255,0), 1)\n",
        "                  cv.putText(frame, \"{}\".format(label) , (left, top - 5), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n",
        "\n",
        "                else:\n",
        "                  label = \"SUV\"\n",
        "                  cv.rectangle(frame, (left, top), (right, bottom), (0,0,128), 1)\n",
        "                  cv.putText(frame, \"{}\".format(label) , (left, top - 5), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,128), 2)\n",
        "                \n",
        "\n",
        "                sedan = sedan + sedanres\n",
        "                suv = suv + suvres\n",
        "                i = i + 1\n",
        "\n",
        "            #GET THE RESULTS OF THE FRAME AND PUT THEM INTO A TUPLE \n",
        "            x = (sedan, suv, total_vehicles)\n",
        "            output.append(x)\n",
        "            img_array.append(frame)\n",
        "            main_end = timeit.default_timer()\n",
        "\n",
        "            throughput_times.append(main_end - main_start)\n",
        "\n",
        "\n",
        "            #IF WE ARE DONE \n",
        "            if (counter == 900):\n",
        "              stop = timeit.default_timer()\n",
        "              print('Throughput (FPS) with optimization of part 2 is: ', (900 / (stop - start))) \n",
        "              throughput_times.append()\n",
        "              height, width, layers = frame.shape\n",
        "              size = (width, height)\n",
        "\n",
        "              #HERE IS WHERE WE CREATE THE VIDEO \n",
        "              out = cv.VideoWriter('/content/output_video.avi', cv.VideoWriter_fourcc(*'DIVX'), 30, size)\n",
        "              for i in range(len(img_array)):\n",
        "                  out.write(img_array[i])\n",
        "\n",
        "              out.release()\n",
        "              cv.destroyAllWindows()\n",
        "\n",
        "              self.stop()\n",
        "\n",
        "    def stop(self):\n",
        "      self._is_running = False\n",
        " \n",
        "#CREATE AND START THE PRODUCER AND CONSUMER THREADS \n",
        "produce = ProducerThread()\n",
        "consume = ConsumerThread()\n",
        "threads.append(produce)\n",
        "threads.append(consume)\n",
        "produce.start()\n",
        "consume.start()\n",
        "\n",
        "for t in threads:\n",
        "    t.join()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Throughput (FPS) with optimization of part 1 is:  23.665129501791096\n",
            "Throughput (FPS) with optimization of part 2 is:  6.304217947947091\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception in thread Thread-30:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"<ipython-input-19-10335719028a>\", line 158, in run\n",
            "    throughput_times.append()\n",
            "TypeError: append() takes exactly one argument (0 given)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sv2VNPNqDy44",
        "outputId": "c08a180b-146b-4fa7-ab29-cf81289f233b"
      },
      "source": [
        "print(\"The average Throughput time is \", (sum(throughput_times)/len(throughput_times)))\n",
        "\n",
        "with open('/content/results.csv','w') as out:\n",
        "    csv_out=csv.writer(out)\n",
        "    csv_out.writerow(['Q1 Times','Q2 Times', 'Throughput'])\n",
        "    for i in range(len(throughput_times)):\n",
        "        resnew = ((i), (throughput_times[i]))\n",
        "        csv_out.writerow(resnew)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The average Throughput time is  0.19342741207565672\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drj9gdm5kGoS"
      },
      "source": [
        "import csv\n",
        "\n",
        "#HERE WE CALCULATE THE F1 SCORES OF ALL THE OUTPUTS\n",
        "f_pos_sedan = 0\n",
        "t_pos_sedan = 0\n",
        "f_neg_sedan = 0\n",
        "\n",
        "\n",
        "f_pos_suv = 0\n",
        "t_pos_suv = 0\n",
        "f_neg_suv = 0\n",
        "\n",
        "f_pos_total = 0\n",
        "t_pos_total = 0\n",
        "f_neg_total = 0\n",
        "\n",
        "#LOOP THROUGH ALL THE RESULTS OF THE 900 FRAMES \n",
        "for i in range(len(res)):\n",
        "\n",
        "  #CALCULATE THE F1 SCORE FOR SEDANS \n",
        "  fp_val = res[i][0] - sedans[i]\n",
        "  if (fp_val >= 0):\n",
        "    f_pos_sedan = f_pos_sedan + abs(fp_val)\n",
        "\n",
        "  fn_val = sedans[i] - res[i][0]\n",
        "  if (fn_val >= 0):\n",
        "    f_neg_sedan = f_neg_sedan + abs(fn_val)\n",
        "\n",
        "  if (res[i][0] >= sedans[i]):\n",
        "    t_pos_sedan = t_pos_sedan + sedans[i]\n",
        "  else:\n",
        "    t_pos_sedan = t_pos_sedan + res[i][0]\n",
        "\n",
        "\n",
        "  #CALCULATE THE F1 SCORE FOR SUVS\n",
        "  fp_val = res[i][1] - suvs[i]\n",
        "  if (fp_val >= 0):\n",
        "    f_pos_suv = f_pos_suv + abs(fp_val)\n",
        "\n",
        "  fn_val = suvs[i] - res[i][1]\n",
        "  if (fn_val >= 0):\n",
        "    f_neg_suv = f_neg_suv + abs(fn_val)\n",
        "\n",
        "  if (res[i][1] >= suvs[i]):\n",
        "    t_pos_suv = t_pos_suv + sedans[i]\n",
        "  else:\n",
        "    t_pos_suv = t_pos_suv + res[i][1]\n",
        "\n",
        "\n",
        "  #CALCULATE THE F1 SCORE FOR THE TOTAL VEHICLES (PART 1 THE YOLO OUTPUT)\n",
        "  fp_val = res[i][2] - total[i]\n",
        "  if (fp_val >= 0):\n",
        "    f_pos_total = f_pos_total + abs(fp_val)\n",
        "\n",
        "  fn_val = total[i] - res[i][2]\n",
        "  if (fn_val >= 0):\n",
        "    f_neg_total = f_neg_total + abs(fn_val)\n",
        "\n",
        "  if (res[i][2] >= total[i]):\n",
        "    t_pos_total = t_pos_total + sedans[i]\n",
        "  else:\n",
        "    t_pos_total = t_pos_total + res[i][2]\n",
        "\n",
        "\n",
        "#HERE WE GET THE F1 SCORE \n",
        "score_sedan = ((t_pos_sedan)/(t_pos_sedan + .5*(f_pos_sedan + f_neg_sedan)))\n",
        "score_suv = ((t_pos_suv)/(t_pos_suv + .5*(f_pos_suv + f_neg_suv)))\n",
        "score_total = ((t_pos_total)/(t_pos_total + .5*(f_pos_total + f_neg_total)))\n",
        "\n",
        "print(\"The f score for part 1 (the YOLO detection results): \", \"{:.2f}\".format(score_total[0] * 100), \"%\")\n",
        "print(\"The f score for the Sedan results are: \", \"{:.2f}\".format(score_sedan[0] * 100), \"%\")\n",
        "print(\"The f score for the SUV results are: \", \"{:.2f}\".format(score_suv[0] * 100), \"%\")\n",
        "\n",
        "#print(res)\n",
        "\n",
        "#WRITE OUR RESULTS TO A CSV FILE \n",
        "with open('/content/results_per_frame.csv','w') as out:\n",
        "    csv_out=csv.writer(out)\n",
        "    csv_out.writerow(['Frame#','Sedan','SUV', 'Total'])\n",
        "    for i in range(len(res)):\n",
        "        print(res[i])\n",
        "        resnew = ((i+1,) + res[i])\n",
        "        csv_out.writerow(resnew)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}